---
permalink: /
title: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---
I am a PhD Student at the [University of Tübingen](https://uni-tuebingen.de/en/) and the [International Max Planck Research School (IMPRS) for Intelligent Systems (IS)](https://imprs.is.mpg.de/). I am co-supervised by [Oliver Bringmann](https://www.embedded.uni-tuebingen.de/team/oliver-bringmann/) and [Wieland Brendel](https://scholar.google.de/citations?user=v-JL-hsAAAAJ). Before my PhD, I have obtained a B.Sc. and a M.Sc. in Physics at the [Karlsruhe Institute of Technology](https://www.kit.edu/english/index.php). During my Master's, I have participated in several research projects centered around numerical optics, and my Master thesis has been published at [Nature Communications](https://www.nature.com/articles/s41467-019-13748-4).

During my PhD, I have been working on improving the **generalization capabilities of Deep Neural Networks** beyond their training distribution. I have explored how we can make vision models more robust to **distribution shifts**. Beyond investigating different robustification methods, I have also analyzed the benefits of **continual learning** when the model is allowed to adapt to the encountered distribution shifts.

In my recent works, I am trying to understand how the OOD generalization capabilities of popular foundation models trained on large-scale datasets can be benchmarked. I also find it intriguing to investigate how **multi-modality** affects the learned representations and their generalizability.

I have completed a research internship at FAIR under the guidance of [Ari Morcos](https://www.arimorcos.com/) and [Kamalika Chaudhuri](https://cseweb.ucsd.edu/~kamalika/). During that internship, I have been working on pruning of large-scale datasets for CLIP training. This work has been published at [ICLR 2024](https://openreview.net/forum?id=CtOA9aN8fr). I have also completed an internship as a student researcher at Google Deepmind under the guidance of [Olivier Hénaff](https://www.olivierhenaff.com/) as a member of the Active Learning team.

Latest publications (ICLR 2024)
======

[**Effective pruning of web-scale datasets based on complexity of concept clusters**](https://openreview.net/forum?id=CtOA9aN8fr)\
Amro Abbas\*, <ins>Evgenia Rusak</ins>\*, Kushal Tirumala, Wieland Brendel, Kamalika Chaudhuri, Ari S. Morcos, *ICLR 2024*

We propose a pruning method where we aim to obtain optimal dataset coverage by assessing the complexity of different concepts; we report competitive results on the DataComp Medium benchmark and outperform regular OpenCLIP training on LAION with significantly less data. This project has also been presented as an **oral** contribution at the [DataComp Workshop at ICCV 2024](https://www.datacomp.ai/workshop.html).


[**Does CLIP’s generalization performance mainly stem from high train-test similarity?**](https://openreview.net/forum?id=tnBaiidobu)\
Prasanna Mayilvahanan\*, Thaddäus Wiedemer\*, <ins>Evgenia Rusak</ins>, Matthias Bethge, Wieland Brendel, *ICLR 2024*

CLIP's ability to generalize to standard OOD benchmarks does not mainly stem from highly similar images in its training dataset.
This project has also been presented as an **oral** contribution at the [Workshop on Distribution Shifts (DistShift) at NeurIPS 2023](https://sites.google.com/view/distshift2023).


[**Removing High Frequency Information Improves DNN Behavioral Alignment**](https://openreview.net/forum?id=Ho0x9DgdZw)\
Max Wolff,  <ins>Evgenia Rusak</ins>, Wieland Brendel, *Workshop on Representational Alignment, ICLR 2024*

Removing high-frequency information by applying blur and resize transformations dramatically improves the model's alignment with humans according to shape-bias and error-consistency.

[More publications](https://evgeniarusak.github.io/publications)


